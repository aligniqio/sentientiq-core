Per-agent feature plugs (quick specialization hints)

Emotion: heavier weight on intensity, velocity; add variance of emotions.

Truth/Brutal: boost authenticity, penalize bot_score and duplicate fingerprints.

Identity: add author profile entropy, past brand affinity.

ROI: lagged conversion proxy (if available), engagement quality.

Warfare: competitor topic spikes, negative intensity deltas.

Pattern: seasonal/diurnal features.
(Implement as simple if agent==...: df["feature_x"]=... in build_features.py.)

Minimal EVI “calculator stub” (standalone)

cli/evi_calc.py

#!/usr/bin/env python3
import argparse, pandas as pd
from libs.evi import compute_evi

if __name__ == "__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--csv", required=True, help="Input CSV with ts,intensity,engagement_rate,authenticity_mean,consensus")
    ap.add_argument("--out", required=True, help="Output CSV with ts,evi")
    args=ap.parse_args()
    df=pd.read_csv(args.csv, parse_dates=["ts"])
    out=compute_evi(df)
    out.to_csv(args.out, index=False)
    print("Wrote", args.out)


Partitioning strategy (Athena-friendly)

Processed: platform=…/ingest_date=YYYY-MM-DD/ (optionally brand if sparsity justifies).

Feature Store: agent=…/window=minute|hour/dt=YYYY-MM-DD/

EVI TS: agent=…/dt=YYYY-MM-DD/

Keep partitions ≤ ~10k files/day to avoid small-file drag (coalesce in writer).

Cost caps (quick set)

Athena WorkGroup: set data scan limit; compress with Parquet; select partitions.

S3 lifecycle: 30-day → Intelligent-Tiering; 7-day expiry for temp/intermediate.

Jobs: prefer small Fargate (0.5–1 vCPU) hourly; scale out later.

What’s included & where to paste

IaC: Terraform snippets (S3 security, IAM).

Athena/Glue DDL: create DB + tables (paste in Athena).

Jobs: enrich_social.py, build_features.py, publish_pulse_snapshot.py.

Training: train_agent.py, run_all.sh, promote.py.

Serving: api/pulse.py, api/ask.py, api/feedback.py.

EVI: libs/evi.py, cli/evi_calc.py.

README: included above (copy to README.md).